name: Python application with Integration Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Cache Ollama models
        uses: actions/cache@v4
        with:
          path: ollama-data
          key: ${{ runner.os }}-ollama-gemma-2b

      - name: Start Ollama
        run: |
          mkdir -p ollama-data
          docker run -d -v ${{ github.workspace }}/ollama-data:/root/.ollama -p 11434:11434 --name ollama ollama/ollama

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          sudo apt-get update && sudo apt-get install -y curl

      - name: Wait for Ollama to be ready
        run: |
          echo "Waiting for Ollama service to start..."
          timeout 60s bash -c 'until curl -s -f http://localhost:11434/api/tags > /dev/null; do echo "Still waiting..."; sleep 2; done'
          echo "Ollama service is up and running!"

      - name: Pull LLM model if not cached
        run: |
          # Check if the model already exists via API (since ollama CLI is not on host)
          if [ $(curl -s -o /dev/null -w "%{http_code}" -d '{"name": "gemma:2b"}' http://localhost:11434/api/show) -ne 200 ]; then
            echo "Model not found in cache, pulling from registry..."
            curl -N -X POST http://localhost:11434/api/pull -d '{"name": "gemma:2b"}'
          else
            echo "Model 'gemma:2b' restored from cache."
          fi

      - name: Run Unit Tests
        run: python -m pytest -m unit

      - name: Run Integration Tests
        env:
          RUN_INTEGRATION_TESTS: "1"
          LLM_ENDPOINT: "http://localhost:11434/v1"
          LLM_MODEL_NAME: "gemma:2b"
        run: |
          mkdir -p data
          python -m pytest -m integration

      - name: Fix cache permissions
        if: always()
        run: sudo chown -R $USER ollama-data